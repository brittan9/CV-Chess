{"version":3,"sources":["data/trajectory.jpeg","data/shot_graph.jpeg","data/hoop_dataset.jpeg","data/hoop_detect.jpg","data/person_detect.jpg","data/shot_graph_fit.jpg","data/projectile_formula.png","data/ball_mid.jpg","data/ball_leaving.jpg","data/analysis_M_Make.ogv","data/analysis_M_Miss.ogv","data/analysis_B_Miss1.ogv","data/analysis_B_Miss2.ogv","data/shot_stats.png","App.js","data/ball_entering.jpg","index.js"],"names":["App","className","href","src","hoop_dataset","alt","hoop_detect","person_detect","shot_graph","shot_graph_fit","trajectory","projectile_formula","ball_mid","ball_leaving","M_Make","autoplay","controls","width","height","M_Miss","shot_stats","B_Miss1","B_Miss2","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"wJAAe,G,gBAAA,IAA0B,yCCA1B,MAA0B,wCCA1B,MAA0B,0CCA1B,MAA0B,wCCA1B,MAA0B,0CCA1B,MAA0B,2CCA1B,MAA0B,+CCA1B,MAA0B,qCCA1B,MAA0B,yCCA1B,MAA0B,4CCA1B,MAA0B,4CCA1B,MAA0B,6CCA1B,MAA0B,6CCA1B,MAA0B,uC,OC6K1BA,MAzJf,WACE,OACE,sBAAKC,UAAU,MAAf,UACI,oBAAIA,UAAU,aAAd,6BACE,yEACA,2EACA,wCAAU,mBAAGC,KAAK,iDAAR,4BACV,oCAGA,+CACE,ojCAaA,gDACA,0DACE,s0BAQA,8jBAMA,qBAAKD,UAAU,QAAQE,IAAKC,EAAcC,IAAI,4BAChD,mEACE,+ZAKA,2fAMA,wSAIA,gCACE,qBAAKJ,UAAU,qBAAqBE,IAAKG,EAAaD,IAAI,wDAC1D,qBAAKJ,UAAU,qBAAqBE,IAAKI,EAAeF,IAAI,kDAEhE,0FACE,i+BAUA,qBAAKJ,UAAU,QAAQE,IAAKK,EAAYH,IAAI,gCAC5C,qBAAKJ,UAAU,QAAQE,IAAKM,EAAgBJ,IAAI,kDAChD,gCACE,qBAAKJ,UAAU,qBAAqBE,IAAKO,EAAYL,IAAI,oCACzD,qBAAKJ,UAAU,qBAAqBE,IAAKQ,EAAoBN,IAAI,kEAEnE,8nBAOA,qBAAKJ,UAAU,QAAQE,ICzGtB,k1MDyG0CE,IAAI,uBAC/C,qBAAKJ,UAAU,QAAQE,IAAKS,EAAUP,IAAI,qBAC1C,qBAAKJ,UAAU,QAAQE,IAAKU,EAAcR,IAAI,sBAC9C,qDACA,iuBAQA,uBAAOJ,UAAU,QAAQE,IAAKW,EAAQC,UAAQ,EAACC,UAAQ,EAACC,MAAM,MAAMC,OAAO,QAC3E,uBAAOjB,UAAU,QAAQE,IAAKgB,EAAQJ,UAAQ,EAACC,UAAQ,EAACC,MAAM,MAAMC,OAAO,QAC3E,8BACE,qBAAKjB,UAAU,qBAAqBE,IAAKiB,EAAYf,IAAI,sCAE7D,yCACE,i9BAUA,uBAAOJ,UAAU,QAAQE,IAAKkB,EAASN,UAAQ,EAACC,UAAQ,EAACC,MAAM,MAAMC,OAAO,QAC5E,uBAAOjB,UAAU,QAAQE,IAAKmB,EAASP,UAAQ,EAACC,UAAQ,EAACC,MAAM,MAAMC,OAAO,QAC9E,4CACE,wDACE,61CAaF,6CACE,8mCAWF,qDACE,4BAAG,mBAAGhB,KAAK,oFAAR,mEACH,4BAAG,mBAAGA,KAAK,oEAAR,qDACH,4BAAG,mBAAGA,KAAK,+CAAR,oEACH,4BAAG,mBAAGA,KAAK,wBAAR,4EACH,4BAAG,mBAAGA,KAAK,8CAAR,kCACH,4BAAG,mBAAGA,KAAK,+DAAR,kDEnKnBqB,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,U","file":"static/js/main.e168c339.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/trajectory.0c86aac1.jpeg\";","export default __webpack_public_path__ + \"static/media/shot_graph.0b3720fb.jpeg\";","export default __webpack_public_path__ + \"static/media/hoop_dataset.477e805c.jpeg\";","export default __webpack_public_path__ + \"static/media/hoop_detect.c9d993d8.jpg\";","export default __webpack_public_path__ + \"static/media/person_detect.3ba8b459.jpg\";","export default __webpack_public_path__ + \"static/media/shot_graph_fit.da3686d3.jpg\";","export default __webpack_public_path__ + \"static/media/projectile_formula.56da6552.png\";","export default __webpack_public_path__ + \"static/media/ball_mid.8d880a41.jpg\";","export default __webpack_public_path__ + \"static/media/ball_leaving.a86ac4f5.jpg\";","export default __webpack_public_path__ + \"static/media/analysis_M_Make.7022644d.ogv\";","export default __webpack_public_path__ + \"static/media/analysis_M_Miss.b74c33ea.ogv\";","export default __webpack_public_path__ + \"static/media/analysis_B_Miss1.ec76a185.ogv\";","export default __webpack_public_path__ + \"static/media/analysis_B_Miss2.a7240977.ogv\";","export default __webpack_public_path__ + \"static/media/shot_stats.c59e465c.png\";","import './App.css';\nimport 'bootstrap/dist/css/bootstrap.min.css';\nimport trajectory from './data/trajectory.jpeg'\nimport shot_graph from './data/shot_graph.jpeg'\nimport hoop_dataset from './data/hoop_dataset.jpeg'\nimport hoop_detect from './data/hoop_detect.jpg'\nimport person_detect from './data/person_detect.jpg'\nimport shot_graph_fit from './data/shot_graph_fit.jpg'\nimport projectile_formula from './data/projectile_formula.png'\nimport ball_entering from './data/ball_entering.jpg'\nimport ball_mid from './data/ball_mid.jpg'\nimport ball_leaving from './data/ball_leaving.jpg'\nimport M_Make from './data/analysis_M_Make.ogv'\nimport M_Miss from './data/analysis_M_Miss.ogv'\nimport B_Miss1 from './data/analysis_B_Miss1.ogv'\nimport B_Miss2 from './data/analysis_B_Miss2.ogv'\n// import Overview from './data/overview_vid.ogv'\nimport shot_stats from './data/shot_stats.png'\n\n\nfunction App() {\n  return (\n    <div className=\"App\">\n        <h1 className=\"App-header\">Nothing But Net</h1>\n          <h5>CSE 455 Computer Vision - Final Project</h5>\n          <h5>Team: Micah Witthaus and Brittan Robinett</h5>\n          <h5>Code: <a href=\"https://github.com/brittan9/CV-Nothing-But-Net\">GitHub Repo</a></h5>\n          <section>\n          {/* <h2>Project Overview Video</h2> */}\n            {/* <video className=\"photo\" src={} autoplay controls width=\"960\" height=\"540\"/> */}\n          <h2>Project Goals</h2>\n            <p>\n              Inspired by one of our shared hobbies and being stuck inside this year, our team wanted to use\n              our newfound computer vision and machine learning skills to analyze video of basketball shots. \n              Our initial goal was to be able to take video with a mobile device of someone shooting hoops \n              and determine both the angle of their shot and whether it makes it into the hoop or not. We added some constraints\n              to this problem by limiting the use case to hoops with a net, videos shot perpendicular to the player and the hoop, as well\n              as requiring stable footage. Knowing the shot angle is helpful for players of all levels of experience, from beginner to professional.\n              Many people have analyzed the physics behind a basketball shot and determined the \"optimal\" angle for release\n              and entry - one source reported between 35 and 55 degrees depending on player height and shot distance. \n              While it's not a one-fits-all approach, the release angle does directly impact the outcome, and thus it's good to know \n              when analzying your performance and consistency. \n            </p>\n            </section>\n            <h2>Implementation</h2>\n            <h4>Data Collection and Prep</h4>\n              <p>\n                In order to detect the basketball hoop in our video, we needed to train a neural net by providing as many images of hoops\n                as we could reasonably find. Our first approach was going out and taking photos of around 10 hoops near us - but we quickly realized\n                that it wouldn't be enough in terms of quantity and variety. Because of this, we padded out the rest of our dataset with\n                images found online. We got a variety of images containing empty courts or people playing, indoor or outdoor courts, and a variety of \n                different looking basketball hoops and nets (we required there to be a net for our purposes). Finally, we used Roboflow to label bounding boxes, \n                augment, split into train/test/validation, and export in the correct format for training. Our final dataset contained 813 images (after augmentation).\n              </p>\n              <p>\n                For testing our application, we took several videos on mobile devices at 3 different locations on different days (one day was shot handheld and the other day we used a tripod). \n                These videos also included people of different heights. Because of COVID, we were unable to take our own video at any indoor courts\n                but based on our testing we believe that our application would likely perform better indoors because outdoors we had a great deal of background\n                movement from cars, trees, etc. skewing our algorithm's perception of where the ball is. \n              </p>\n              <img className=\"photo\" src={hoop_dataset} alt=\"some labelled hoop data\"/>\n            <h4>Object Detection: Hoop and Person</h4>\n              <p>\n                Our team chose to use Yolov5 for object detection because YOLO object detection methods are fast and accurate compared to other methods\n                like Fast R-CNN. Yolov5 offers compatability with PyTorch and Colab, and has a \"small\" version that seemed perfect for our purposes since\n                it runs extremely fast (we were considering running on a mobile device but didn't get to this due to time).\n              </p>\n              <p>\n                Because Yolov5 trains in Google Colab, we trained once using our custom dataset and saved the best performing weights over 60 epochs. \n                The best mAP we achieved was around 0.9 for a confidence of 50% and above. The custom dataset tutorial we referenced is linked in the \n                References section. For detecting the person shooting in the image, we use a version of Yolov5 pretrained on the COCO dataset loaded \n                from PyTorch Hub, and constrained it only to detect Class 0, or \"Person\". \n              </p>\n              <p>\n                If the algorithm detects multiple hoops or multiple people, it chooses the one it detects with highest confidence. Below is a frame\n                from one of our testing videos showing the basktball hoop detected with 85% confidence and the person detected with 91% confidence.\n              </p>\n              <div>\n                <img className=\"photo resize-photo\" src={hoop_detect} alt=\"shot photo with bounding box around basketball hoop\"/>\n                <img className=\"photo resize-photo\" src={person_detect} alt=\"shot photo with bounding box around person\"/>\n              </div>\n            <h4>Shot Analysis: Trajectory Fitting and Shot Classifcation</h4>\n              <p>\n                Using the bounding box of the person and the hoop, we are able to locate the area that would contain the arc of the shot\n                which we then looked for moving pixels within in order to isolate the movement of the ball. We use an OpenCV foreground/background \n                segmentation method that locates all moving pixels in a frame within a threshold to accomplish this. Because we wanted to get the entire\n                shot over multiple frames of video, we built up a list of moving pixel locations and then had to convert them to coordinate locations on a\n                cartesian xy-plane. After we gathered all the moving pixel coordinates, we fit a trajectory curve to our data using an Adam optimizer to get the angle \n                and velocity of our shot. Below on the left is an example of the plotting of a shot arc and on the right is an example of a fitting of a shot arc\n                (on a different image). Underneath those two images is an example of the parameters optimized and the trajectory formula used \n                to do so.\n              </p>\n              <img className=\"photo\" src={shot_graph} alt=\"shot graph of moving pixels\"/>\n              <img className=\"photo\" src={shot_graph_fit} alt=\"shot graph of moving pixels fitted with curve\"/>\n              <div>\n                <img className=\"photo resize-photo\" src={trajectory} alt=\"trajectory curve with variables\"/>\n                <img className=\"photo resize-photo\" src={projectile_formula} alt=\"projectile formula used for finding the angle and velocity\"/>\n              </div>\n              <p>\n                To determine whether or not the shot made it in, we check for moving pixels in a region above the rim of the hoop, and if there is enough\n                movement in that region, we start checking for moving pixels in a region below the net (both need to be passed through for the shot to count).\n                This is important because we may detect moving pixels above, next to, behind, or generally near the rim/net without it actually passing \n                through the net. Below is three images of our motion mask in the region of the hoop - from left to right we're showing\n                a ball entering the hoop, inside the hoop, and then leaving the hoop.\n              </p>\n              <img className=\"photo\" src={ball_entering} alt=\"ball entering hoop\"/>\n              <img className=\"photo\" src={ball_mid} alt=\"ball inside hoop\"/>\n              <img className=\"photo\" src={ball_leaving} alt=\"ball leaving hoop\"/>\n              <h4>Displaying Analysis</h4>\n              <p>\n                In order to display the results of the shot analysis to the user we chose to make a text file, called \"shot_stats.txt\", containing the shot number,\n                the angle of the shot, and whether it was made or not for each shot they passed into the program. At the bottom of the \n                of the text file we display the total number of shots made out of the the total number of shot attempts, the percentage \n                of shots made, and the average shot angle. We also save new video files with the same names as the previous ones with the \n                exception of \"_analysis.avi\" tacked on to the end of them that contain the original video with the shot arc overlayed on it \n                (the shot arc is red for shots detected as misses and green otherwise).\n              </p>\n              <video className=\"photo\" src={M_Make} autoplay controls width=\"640\" height=\"360\"/>\n              <video className=\"photo\" src={M_Miss} autoplay controls width=\"640\" height=\"360\"/>\n              <div>\n                <img className=\"photo resize-photo\" src={shot_stats} alt=\"text file containing shot stats\"/>\n              </div>\n            <h2>Results</h2>\n              <p>\n                  We tested with 11 videos of shots going in and 29 videos of shot misses, and correctly classified 35 out of the 40.\n                  We had 86% accuracy on classifying misses and 90% accuracy on classifying shots made. The accuracy of the shot angle is\n                  difficult to determine, however, we noticed that with the stable footage (shot with a tripod) our curve fit the trajectory\n                  of the ball pretty well in each video. Shooting handheld introduced noise into our moving pixel data, which tended to pull\n                  the shot arc downwards as well as give false positives to missed shots. After examining the cases in which our algorithm \n                  classified a shot as making it when it shouldn't have, it's apparent to us that we would need to take a different approach \n                  to avoid this type of misclassification (explored in 'Reflection'). For example, the videos included below show ball behavior which could appear to go both\n                  above and below the hoop, even though it doesn't pass through. \n              </p>\n              <video className=\"photo\" src={B_Miss1} autoplay controls width=\"640\" height=\"360\"/>\n              <video className=\"photo\" src={B_Miss2} autoplay controls width=\"640\" height=\"360\"/>\n            <h2>Reflection</h2>\n              <h4>Alternative Approaches</h4>\n                <p>\n                One problem we encountered was background movement introducing noise into the coordinate data we used to fit our trajectory \n                curve; this problem was especially apparent on the footage we shot handheld. An alternative approach that would circumvent\n                this problem would be to track the basketball throughout the frames in the video using yolov5 and take the coordinates from\n                the center of its bounding box. This approach has two methods of implementation; the first would be to use a version of yolov5\n                pre-trained on the COCO dataset and use the class sports ball to locate the basketball, the second would be to create a custom\n                dataset of various types of basketballs and train yolov5 on it in order to do the detection. We ended up foregoing these approaches\n                for a few reasons. Firstly, if we used the pretrained yolov5 we didn't think that sportsball represented what we were trying to detect\n                as much as a custom dataset could. Secondly, if we chose to create a custom dataset we didn't think we would have enough data to create\n                a representive group of basketballs of different styles in various environments (different lighting, position, etc). Lastly,\n                one of our biggest concerns was how well the basketball detection would work as the ball passes through the hoop since this is an\n                integral part of detecting whether a shot went in or not.\n                </p>\n              <h4>Future Work</h4>\n                <p>\n                There is a lot of functionality that could be built onto this project and our team plans to continue work on it when we can!\n                In the future we might implement a hybrid of the approach discussed in \"Alternative Approaches\" and what we implemented, where we use\n                the basketball tracking until the ball reaches the hoop then use motion tracking to see if the shot was made. Another thing \n                we would want to be able to do is take video from any location on the court instead of needing to be \n                perpendicular to the shot - this could be achieved using a translation and mapping to 2D space, or alternatively\n                could be done by using a 3D trajectory formula if you can determine the precise player location on the court (potentially using homographies).\n                Additionally, for usability we really want users to be able to have shot analysis run directly on their mobile device instaed of needing to\n                upload to a laptop or home computer. Lastly, another functionality we would like to implement is the ability for our algorithm to\n                trim videos automatically by recognizing what a shot looks like using binary classifcation.\n                </p>\n              <h2>Links to References</h2>\n                <p><a href=\"http://www.ijac.net/fileIJAC/journal/article/ijac/2021/2/PDF/IJAC-2020-05-119.pdf\">Camera-based Basketball Scoring Detection Using CNN</a></p>\n                <p><a href=\"https://www.noahbasketball.com/blog/is-a-higher-arc-really-better\">Information on basketball shot angles</a></p>\n                <p><a href=\"https://www.youtube.com/watch?v=S9PcPbtTcPc/\">Shooting Hoops with Keras and Tensorflow - Zack Akil</a></p>\n                <p><a href=\"https://roboflow.com/\">Roboflow - Used for Creating Custom Object Detection Dataset</a></p>\n                <p><a href=\"https://pytorch.org/hub/ultralytics_yolov5/\">PyTorch Hub Yolov5</a></p>\n                <p><a href=\"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\">Yolov5 on Custom Data Tutorial</a></p>\n    </div>\n  );\n}\n\nexport default App;\n","export default \"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCADRAKcBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AP5/6KKK9I/ZP/ZG/aL/AG4/jbpv7On7LHwzuPFnjHVre5ns9Khvbe1XyoIWmlkknuZI4YVCIfmkdQzFUGWdVP7Df8E/f+DMH4mfETwqnjj/AIKL/G/UPh9dnUAn/CA+CobK+umtdltJ5r6l5ssEUuWuYTEsEqq0aSCR1Ow/p/8ADT/g2d/4IlfC/wAm4079iLT9Xu009bWe88TeKdW1H7RjYWlaGe7aBJWKAlo40xuYKFUla6jVv+DfT/gjJrWlXOj3n/BPvwOkN3bvDK9p9qt5VVlKkpLFMrxtg8OjBlOCCCAa+J/2pP8Agzi/ZD8YeFfFerfs5+OtQ8I6n/p194S0jT7a5usPsla10+SW/wBRkV4tzRK0h8tzsB3qC2fx5/4KMf8ABAT/AIKM/wDBNfSr34ifFf4X2+v+AItYksbPxx4V1GG7ikAW5lSSa1Vzc2ymC1eZnePyowyq0m87a+KKKKKKKKKKKKKKK9H/AGTP2Z/GX7XXx50L4FeCr63sZtWuP9M1e+IW1023GN88zsVSNclUDSPHHvkRWkQNuH9R3/BCz/gjF4U/YB8A2Pj+31zR9Vh8UeF9G1iDxLpj6rp+vahezRR3M8F80V6LVtPibYkNn5Mm795JJIxcpX6T1X1ayudR0q50+z1a4sJp7d44r+0WNpbZmUgSIJUdCyk7gHVlyBlSMg2KKz/EfhbQfF1mumeJLH7XafvBNYyyt5FykkMkLxTxA7LiJklcGOQMmdrbdyKR/MD/AMHLX/BA/Qv+Cd2vJ+2f+yrbeX8IvFniBbHUvC6hnfwpqUyySIkZwc2MnluELHMT7YiTvjr8kaKKKKKKKKKKKK/pV/4Nyv8Agkv8EvgT4NtIP2mvhbcXXj/xz4H0Xx/DZ+IZ5tsunSkG2jW2glEUC27ySRzQ3YkluGuFOyFInjf9f/Atl4M8Har/AMKk8IatcRQ+HPC+lx23h5lLRWFluuobeRZWTfI0gt3Rg0r4Fsh2oWZpOg1bTLbWtKudGvJLhIbu3eGV7S7kt5VVlKkpLEyvG2Dw6MGU4IIIBo0nTLbRdKttGs5Lh4bS3SGJ7u7kuJWVVCgvLKzPI2By7sWY5JJJJqxRVfU9TttJtlurqO4dXuIYQLa0knbdJIsakrGrEKGYFnI2ooZ2KqrMPB/+CmH7KPgn9ur9kfxf+yZ4ri0+7uPEfh+9utM02SG2a/knt4j5E1k9ySltKl1LaA3BRwiyFPkMqyJ/FH8WPhvrvwb+KfiX4Q+KbzT7jU/CviC90fUbjSb5bq1lntp3gkaGZPlliLISrrwykEcGufoooooooooor6H/AOCSvwG8G/tN/wDBTH4HfA34jWVvd+Htd+JGmLr2n3duZYr+yimE89o6hlO2aOJoSc/KJCcHGD/abp03h74aaVovws+H/he4vodJt7CwXSdN1C3aXSNOKvDDdTi5nRzAot3XcvmSuY22q5VsdRRRRRRXP/FnQPFXiz4V+JvC3gXW/wCzdb1Lw/e2ujaj9peH7LdSQOkUvmRgum1yrblBYYyBkV/Hl/wcIeFtd8P/APBYH43atq9j5NvrnjC4vtLk81W8+BXNsXwpJX97bzLhsH5M4wQT8YUUUUUUUUUUV9/f8G0n/KU3wn9bD/0+aXX9e1lpOladc3d5p+mW8E1/cCe/lhhVWuZRGkQkkIGXYRxxpuOTtjUdFAFfSNE/sS8uYdMh0+20yXM0VlZ6f5TrdSTTS3MzuH2v5rSK2Nitv8xmZzIAmhRRRRRX8YX/AAX3/wCUyX7Qn/ZQJv8A0TFXyBRRRRRRRRRRX0v/AMEmfjd8Hv2bP2x9B+PPxw+INvpWh+GbiwmuNA1DTruey8URS6rYW1zY3RtYZ2ighs57rUWLQTCT+yxCsZlmiI/qW+Nf/BwT/wAEpf2a/FVv4F/aM+OvjDwBrd3p6X9ro3jX4G+MdKuprVnkjW4SK60lHaIvFKgcDaWjcZypxx//ABFHf8EKP+j5v/MZeJ//AJWVoW3/AAcw/wDBFG88K3vjqz/bA1CXRNO1C2sNQ1mP4TeK2tbW6uUnkt7eSUaXsSWVLW6dEYhnW2mKgiNsaHxZ/wCDjz/gjH8Dvin4m+CnxS/bJ/svxP4P8QXuieI9M/4V54in+yX9pO8FxD5kOnvHJsljddyMytjKkgg1z/8AxFHf8EKP+j5v/MZeJ/8A5WVoW3/BzD/wRRvPCt746s/2wNQl0TTtQtrDUNZj+E3itrW1urlJ5Le3klGl7EllS1unRGIZ1tpioIjbGf8A8RR3/BCj/o+b/wAxl4n/APlZWf4s/wCDp/8A4Ii6P4V1PVvC37Yf9sana6fNNp2kf8K+8S2/26dULRwea+mFYt7ALvbhd2TwK/k6+N3xQ1X43/Gjxf8AGjXRcC+8X+KNQ1u8F3etcyiW6uZJ33zMAZW3SHLkAsckgZrl6KKKKKKKKKKK9g8G/t6/tY/D/wAR+LPFnhH4rfZNQ8c/B+P4W+Kbj+wrCT7b4Tj06z01NO2vAVjxaafZxefGFnPk7jJvd2avN4td/CVn4c8Q/tQ28WkeGvC8WnaNpfgzQLpbq8N5Y6tqHkSh4bOOdbe+1C4067ubiZ5Y01B/sa39tEFr0f8AZ61b9qf9qD9ljw3/AME5PhJoPiDxb4Jh+MF/8QvGHhH4V/DO+8ReKtPxY6XpZ1iWJVjhlto4ZZYreGO5h3TvOLpo1ezkH0R8KP8Agn9+2v8A8E+fEPxc0u9+Pnwn+Anhz4q/s8ahp51n9pfxPpWj+JtR8JX9xaTXEUHhrTrzVdRt9QuEs57cRG3mZQl1EhS7EQX5X8f/AAt/ZnsfEeian8af+CkX/Cw/tX2bTbjUfhX4C1rWrnSNKstOa3t0lHiUaHnZ5OnWtvbwvIi26zlng+zW8F15hptz8AtB8VeLbPWNG8YeKtEbT7+28Cahbana6BdR3W8Cyv7+3aHUEeIIC01jFMrFn2peAJufP+KWpfCzV/Hd9qHwU8G+IPD/AIYk8r+zNI8U+JoNYv7fESCTzbyCyso5t0okZdtvHtVlQ7ypds/UdZ0690LTtItvCen2dxY+d9p1S3kuDPqG9gy+cJJWiXyx8q+UkeQfn3nms+iiiiiiiiiiiiirGk6nc6LqttrFnHbvNaXCTRJd2kdxEzKwYB4pVZJFyOUdSrDIIIJFfV/xo/4K1/t9/wDBSPxb4a+DX7fP/BQfxRYfDjV9YsNN8XXFho0cOl2WnNfQySX9zpGkx26am1sVFwiOrSloVVGU4x8seE/DOo+NPFWmeDtHudPhu9W1CGytZtW1a3sLVJJXCK011dSRwW0QLAtNK6RouWdlUEjPooooooqxJZW0elQ6gurW7zS3Esb2KrJ5sKqsZWRiUCFXLsFCsWBifcqgoXr0UUUUUUUUUUUUUVY0nTLnWtVttHs5LdJru4SGJ7u7jt4lZmCgvLKypGuTy7sFUZJIAJovdW1XUba0s9Q1O4nhsLcwWMU0zMttEZHlMcYJwimSSR9owN0jHqxJr0UVseNbLwbpmqx6V4K1a41KG1txHearKpSK9uNzF5LeNkV44MFUQSfvHCeYyxGTyIseiiiiiiiiiiiiiiiiiiiirGp6Zc6Tcra3Ulu7PbwzA213HMu2SNZFBaNmAYKwDITuRgyMFZWUV6KKKKKKKKKKKKKKKKKsate22o6rc6hZ6Tb2EM9w8kVjaNI0VsrMSI0Mru5VQcAuzNgDLE5Jr0UUUUUUUUUUUUUUVY0zSdV1q5az0fTLi7mS3mneK2haRliijaWWQhQSFSNHdm6KqsTgAmq9FWI5NKGlTQzWVw181xEbe4W5URJEFk8xGj2EszMYirB1ChHBV94KV6KKKKKKKKKKKKKKKK7jxt4209vhV4U8C6Br2j6gsmjxz69Evw+0+xvdLvYNR1fyrYaikZub5Wt7xZ3lZ13+bb27q66balDwb4Q+A2pfDS/8VeO/jXrGk+IbS4uoLTwrp/gz7a16TaGSymS4a6iiWA3EckF0X2y26y2stvFf+ZcJa8PRRRRRRRRRRRRRRRRViTSdVh0qHXZtMuEsbm4lgt7xoWEUssaxtJGr4wzKssRZQcgSITjcM162PiF4Nufh14+1z4fXmv6Pqs2haxc6dLqnh7VI77T7xoJWiM1tcxEpcQOV3JKhKuhVgSCK2PCmqfD0fBrxf4e8UeKdQs9bl1DSr3wzp1l4DsL2PUJIjcxTrPqstzHd6ZEkNw7iG3iuI7uQRecqG3hlTj6KsaZHpUtyy6xe3EEIt5ij21sszGURsYkKs6AK0gRWbJKKzMFcqEavRRRRRRRRRRRRRWhbeGdRuvCt74xiudPFpYahbWU8MmrW6XTSTpO6NHatIJ5ogLaQPNGjRxM0KyMjTwh9j4b678O9BsfEdx468LW+r3Umj248N213Z3MkX21dSspZA8lvfWrW6vZx3kRkK3PEpRYY5JEvLXl60PDPhPxV401GTR/B3hnUNWu4dPu7+a10yyeeRLW1t5Lq6uCqAkRQ28Ms0jn5Ujid2IVSRn0UUUUUUUUUUUUUUUUV6R4J0z4Jat+zD40tdWkt0+J6eOPD83hI3N3NCv8Awj8em+IJNZAZmW2LG4XRQqSHz3YqkAbdKp83roPhp41/4QHxHc679t8QQef4f1bTd/hrX/7NuT9s064s9jzeVLvtm8/bcW+0fabdpoN8Xm+amPq17bajqtzqFnpNvYQz3DyRWNo0jRWysxIjQyu7lVBwC7M2AMsTkmxrPizxV4j07SdH8Q+JtQv7TQNPaw0K1vb15Y9OtWuJrpreBWJEMRuLm4mKJhTJPK+NzsTn10HhW68baZ4Q8T3nh/xTqGlaRe6fb6br8dvJcpBq6Pdw3MOnzGJTG+ZbRbtY5yqE6fvUmSJAefoooooooooooooooooooroPH/xF1j4gf2Ja3kH2TT/Dvh+20jRNJh1G8uLayhj3STGEXU8zQ/aLuW6vZY42WEXF7cNHHEjiNefoooooooooooooqxHZW0mlTag2rW6TRXEUaWLLJ5sysshaRSEKBUKKGDMGJlTarAOUr0V0HxS1PWNR8d31trPxS/4TX+yvK0jT/E6XF5JDfWFjElnZm3+2xxXCWy20EKQxyxxNHCkaGOPbsXn60NZ0bTtL07Sb6x8WafqMuo6e1xeWdlHcLJpcguJohbTmWJEaUpEk4MLSx+XcxAuJRLFHYi1Pxl4zttE+Henx3F8ttcPDoukWFoC0lxcSDcVSNczTyN5abzukZY4Y8lY41XoPizonwX0jVdbtPAV9rFrc2msRx6XpUmpW2tWzWkjXckok1OKO0Dz2y/YbbMNq8F0/2q4SWGMQxScPRRRRRRRRRRRRRRRRViyj0qS2u21C9uIpktwbFIbZZFml8xAUkYupjXyzI24ByWVV2gMXSxo3hPxV4j07VtY8PeGdQv7TQNPW/wBdurKyeWPTrVriG1W4nZQRDEbi5t4Q74UyTxJnc6g19T0y50m5W1upLd2e3hmBtruOZdskayKC0bMAwVgGQncjBkYKysoL3SdV062tLzUNMuIIb+3M9jLNCyrcxCR4jJGSMOokjkTcMjdGw6qQK9FFFFFFFFFFFFFFFFFFaFt4Z1G68K3vjGK508WlhqFtZTwyatbpdNJOk7o0dq0gnmiAtpA80aNHEzQrIyNPCHr3urarqNtaWeoancTw2FuYLGKaZmW2iMjymOME4RTJJI+0YG6Rj1Yk16KKKKKKKKKKKKKKK0LbwzqN14VvfGMVzp4tLDULaynhk1a3S6aSdJ3Ro7VpBPNEBbSB5o0aOJmhWRkaeEPn0UUUUUUUUUUUUUUUUUUUUUUVoeLLnwreeKtTvPAujahp2iS6hM+jafq2ppe3VralyYopriOGBJ5VTarSrDErsCwjQHaM+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiv/2Q==\"","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n"],"sourceRoot":""}